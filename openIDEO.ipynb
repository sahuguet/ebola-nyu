{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "openIDEO scrapper\n",
      "=================\n",
      "\n",
      "openIDEO contains a list of project ideas related to ebola.\n",
      "\n",
      "The goal of this project is to compute some stats about the projects submitted and identify some trends.\n",
      "\n",
      "The script:\n",
      "* starts from the last project submitted\n",
      "* parses the page to extract project info\n",
      "* extracts the URL of the previous project\n",
      "* goes to the previous projects, until there is no more project\n",
      "\n",
      "Each project gets dumped into a JSON file."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import urllib2\n",
      "import bs4\n",
      "import json\n",
      "import re\n",
      "import sys\n",
      "import time"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# To extract a number at the beginning of a string, e.g. `12 comments`.\n",
      "def asInt(str):\n",
      "    matches = re.findall('\\d+', str)\n",
      "    if len(matches) > 0:\n",
      "        return int(matches[0])\n",
      "    else:\n",
      "        return -1\n",
      "\n",
      "def processComment(comment):\n",
      "    author = comment.find('h4').a.text.strip()\n",
      "    date = comment.find('span', {'class': 'comment-date'}).text.strip()\n",
      "    message = comment.find('div', {'class': 'comment-message'}).text\n",
      "    applaud = comment.find('div', {'class': 'comment-actions'}).find('span', {'class': 'applaud'}).text\n",
      "    return { 'auhtor': author,\n",
      "             'date': date,\n",
      "             'message': message,\n",
      "             'applaud': applaud }\n",
      "\n",
      "def processComments(page_soup):\n",
      "    comments = page_soup.findAll('div', attrs={'class': 'comment'})\n",
      "    comments_data = []\n",
      "    for comment in comments:\n",
      "        comments_data.append(processComment(comment))\n",
      "    return comments_data\n",
      "\n",
      "def processPage(page_soup, id):\n",
      "    page = {}\n",
      "    page['id'] = id\n",
      "    page['title'] = page_soup.findAll('h2', attrs={'class': 'item-title'})[0].text.strip()\n",
      "    page['summary'] = page_soup.findAll('div', attrs={'class': 'summary'})[0].text\n",
      "    page['description'] = str(page_soup.findAll('div', attrs={'class': 'description'})[0])\n",
      "    __submission__ = page_soup.findAll('div', attrs={'class': 'content-submitted-by'})[0]\n",
      "    page['author'] = __submission__.findAll('span', text='Idea submitted by:')[0].parent.find_all('a')[0].text.strip()\n",
      "    page['submitted'] = __submission__.findAll('span', text='Idea submitted by:')[0].parent.find('div').text\n",
      "    page['view_count'] = asInt(__submission__.findAll('span', {'class': 'views'})[0].text)\n",
      "    page['comment_count'] = asInt(__submission__.findAll('span', {'class': 'comments'})[0].text)\n",
      "    page['applause_count'] = asInt(__submission__.findAll('span', {'class': 'votes'})[0].text)\n",
      "    try:\n",
      "        page['tag'] = __submission__.find_all_next('a', attrs={'class': 'assignment-more'})[0].attrs['href']\n",
      "    except Exception, e:\n",
      "        page['tag'] = 'N/A'\n",
      "    page['comments'] = processComments(page_soup)\n",
      "    if page_soup.find('div', id='gallery'):\n",
      "        page['media'] = [ { 'type': k.attrs['class'][-1], 'src': k.attrs['href']} for k in page_soup.find('div', id='gallery').find('div', {'class': 'hidden-gallery'}).find_all('a')]\n",
      "    else:\n",
      "        page['media'] = []\n",
      "    previous = 'https://openideo.com' + page_soup.findAll('a', attrs={\"class\": \"prev\"})[0].attrs['href']\n",
      "    return (previous, page) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "FOLDER = '/Users/sahuguet/Documents/Notebooks/openIDEO'\n",
      "RESEARCH_URL_LAST = 'https://openideo.com/challenge/fighting-ebola/research/scicast-crowdsourced-intervention-effectiveness-predictions-for-designing-and-prioritizing-contextually-appropriate-interventions'\n",
      "# The URL of the last project submitted on the site; go to https://openideo.com/challenge/fighting-ebola/ideas/ .\n",
      "IDEAS_URL_LAST = 'https://openideo.com/challenge/fighting-ebola/ideas/dimeric-flavonoid-the-cure'\n",
      "\n",
      "current_page_url = IDEAS_URL_LAST\n",
      "count = 0\n",
      "while True:\n",
      "    time.sleep(3)\n",
      "    # TODO: we check that we don't already have the page\n",
      "    if current_page_url.find('#')>-1 or count > 500:\n",
      "        print >> sys.stderr, 'end'\n",
      "        break\n",
      "    print >> sys.stderr, 'Processing %s ...' % current_page_url\n",
      "    page_soup = bs4.BeautifulSoup(urllib2.urlopen(current_page_url).read())\n",
      "    filename = current_page_url.split('/')[-1]\n",
      "    (current_page_url, data) = processPage(page_soup, current_page_url)\n",
      "    with open(\"%s/%s.json\" % (FOLDER, filename), 'w') as g:\n",
      "        g.write(json.dumps(data, indent=2, sort_keys=True))\n",
      "        g.close()\n",
      "    count = count + 1\n",
      "    print >> sys.stderr, count"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}